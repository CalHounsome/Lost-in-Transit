{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "358f261c-2678-4d14-b2be-3823056e2fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062fb263-9bb1-4b2f-a210-a3ebd8bf9cf0",
   "metadata": {
    "tags": []
   },
   "source": [
    " # ENTER WEEK YOU ARE CLEANING BELOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf36af23-cd0a-4cc6-9d7e-3e34d06c13cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIT_DATA_WEEK = 'Week 24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67536fff-a63f-44af-85ac-0ee8cc19c4a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths for the Excel files\n",
    "LIT_Outbound = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Outbound Looker\"\n",
    "Financial_Calendar = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Financial Calendar - 20-25.xlsx\"\n",
    "LIT_RTN = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Returns Looker\"\n",
    "OB_Status_Lookup = pd.read_excel(r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Status Lookups.xlsx\", sheet_name = 'OB Status Lookup')\n",
    "RTN_Status_Lookup = pd.read_excel(r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Status Lookups.xlsx\", sheet_name = 'RTN Status Lookup')\n",
    "Master_DATA = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Refund and Exchange Data\"\n",
    "for filename in os.listdir(Master_DATA):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path1 = os.path.join(Master_DATA, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_Master = pd.read_excel(file_path1, sheet_name = LIT_DATA_WEEK)\n",
    "\n",
    "# Future Location for the Template\n",
    "output_dir = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\LIT Output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# Current date for the filename\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# Filename for the Excel output\n",
    "output_filename = f\"LIT {LIT_DATA_WEEK} Outbound & Returns Data {current_date}.xlsx\"\n",
    "output_filepath = os.path.join(output_dir, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3bc3c-55f4-4826-be56-32dfad00deb1",
   "metadata": {},
   "source": [
    "# Step 1: Script for Obtaining Order Numbers to put into Looker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0774fb5b-3511-4b03-9e17-0c3b90b8023c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selecting required row from CS report\n",
    "Rows_Selected=['LIT: No Courier Movements','LIT: Damaged/Confirmed Lost','Returns Issue: No Courier Movements','Returns Issue: Unprocessed Order at DC','Returns Issue: Missing item(s)','Returns Issue: Damaged/Confirmed Lost']\n",
    "OB_rows = ['LIT: No Courier Movements','LIT: Damaged/Confirmed Lost']\n",
    "RTN_rows = ['Returns Issue: No Courier Movements','Returns Issue: Unprocessed Order at DC','Returns Issue: Missing item(s)','Returns Issue: Damaged/Confirmed Lost']\n",
    "df_Master = df_Master[df_Master['Reason Description'].isin(Rows_Selected)]\n",
    "\n",
    "output_dir2 = r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Order Numbers\"\n",
    "if not os.path.exists(output_dir2):\n",
    "    os.makedirs(output_dir2)\n",
    "# Filename for the Excel output\n",
    "output_filename2 = f\"LIT {LIT_DATA_WEEK} Order Numbers {current_date}.xlsx\"\n",
    "output_filepath2 = os.path.join(output_dir2, output_filename2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b1bcf4-be0b-4f14-9b38-78cd77c6bdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join df_Master to FC\n",
    "excel_df = pd.read_excel(Financial_Calendar)\n",
    "selected_columns=['Date','Period','Week','FY']\n",
    "excel_df=excel_df[selected_columns]\n",
    "excel_df['Date'] = pd.to_datetime(excel_df['Date'],dayfirst=True,errors='coerce')\n",
    "excel_df['Period']=excel_df['Period'].astype(object)\n",
    "excel_df['Week']=excel_df['Week'].astype(object)\n",
    "excel_df['FY']=excel_df['FY'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bc2bc9b-b670-4d99-b1cb-6a7bb574994c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join by financial Calendar\n",
    "df_Master= df_Master.merge(excel_df,\n",
    "                                      left_on='Date',\n",
    "                                      right_on='Date',\n",
    "                                      how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05893245-0c90-4f05-876d-ac238d86e736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Order Number Column for OB and RTN\n",
    "selected_column = 'Original Order Number'\n",
    "df_OB_OrderID=df_Master[df_Master['Reason Description'].isin(OB_rows)]\n",
    "df_RTN_OrderID=df_Master[df_Master['Reason Description'].isin(RTN_rows)]\n",
    "df_OB_OrderID = df_OB_OrderID[selected_column]\n",
    "df_RTN_OrderID=df_RTN_OrderID[selected_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18f7e742-1e68-49f4-920c-b36f59cfdf70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_filepath2) as writer:\n",
    "    df_OB_OrderID.to_excel(writer, sheet_name='OB Order Numbers', index=False)\n",
    "    df_RTN_OrderID.to_excel(writer, sheet_name='RTN Order Numbers', index=False)\n",
    "    \n",
    "# THIS WILL PRINT EXCEL SHEET WITH THE ORDER NUMBERS YOU NEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99332b0-f3a1-4ede-981a-b363d22891d7",
   "metadata": {},
   "source": [
    "# Outbound Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20afd667-a285-4f98-b75d-1daca67acc29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, work on cleaning outbound data.\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(LIT_Outbound):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(LIT_Outbound, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_OB = pd.read_csv(file_path)\n",
    "        \n",
    "        \n",
    "        # Join Normalized Status Sheet:\n",
    "        df_OB = df_OB.merge(OB_Status_Lookup,\n",
    "                                        left_on='Latest Carrier Status',\n",
    "                                        right_on='Status',\n",
    "                                        how='left')\n",
    "        \n",
    "        # Convert the 'Date' column to datetime for non-empty date rows\n",
    "        df_OB['Consignor Status Update - Date'] = pd.to_datetime(df_OB['Consignor Status Update - Date'],dayfirst=True)\n",
    "        \n",
    "        # Sort the DataFrame by 'Date' in descending order for non-empty date rows\n",
    "        df_OB = df_OB.sort_values(by='Consignor Status Update - Date', ascending=False)\n",
    "        \n",
    "       # Create a helper column for sorting that puts 'delivered' last - we want to see status's for duplicates that are non delivered\n",
    "        df_OB['SortPriority'] = df_OB['Status Normalized'].apply(lambda x: 1 if x == 'Delivered' else 0)\n",
    "        \n",
    "        # Sort by the helper column first, then by 'Status' if needed - this sorts by date and put delivered status's at the bottom of the dataframe.\n",
    "        df_OB.sort_values(by=['SortPriority', 'Consignor Status Update - Date'], ascending=[True, False],inplace=True)\n",
    "        \n",
    "        # Remove duplicates by 'OrderNumber', keeping the first occurrence - drops the second occurance\n",
    "        df_OB = df_OB.drop_duplicates(subset='Order Number', keep='first')\n",
    "        \n",
    "        # Optionally, drop the helper column if no longer needed\n",
    "        df_OB.drop(columns=['SortPriority'], inplace=True)\n",
    "        \n",
    "# Sort data by most recent date so lookup is dependant on most recent update\n",
    "df_OB_cleaned = df_OB.sort_values(by='Consignor Status Update - Date',ascending=False)\n",
    "df_OB_cleaned['Work Stream']='Outbound'\n",
    "df_OB_cleaned=df_OB_cleaned.drop(columns=['Status','Consignor Status Update - Date'])\n",
    "df_OB_cleaned.rename(columns={'Status Normalized':'Latest Status','Carrier Name':'Carrier','Latest Carrier Status': 'Status Non-Normalized','Order Number':'Original Order Number'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e362cb-623a-4b98-bcc6-b57483372914",
   "metadata": {},
   "source": [
    "# Returns Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdc83873-9507-461f-a687-71886b66528e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Work On Clearing Duplicates (keep most recent requested date if there are).\n",
    "for filename in os.listdir(LIT_RTN):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path2 = os.path.join(LIT_RTN, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df_RTN = pd.read_csv(file_path2)\n",
    "        \n",
    "        \n",
    "        df_RTN = df_RTN.merge(RTN_Status_Lookup,\n",
    "                                        left_on='Last Tracking Status',\n",
    "                                        right_on='Status',\n",
    "                                        how='left')\n",
    "        \n",
    "        # Convert the 'Date' column to datetime for non-empty date rows\n",
    "        df_RTN['Requested Date'] = pd.to_datetime(df_RTN['Requested Date'],dayfirst=True)\n",
    "        \n",
    "        # Sort the DataFrame by 'Date' in descending order for non-empty date rows\n",
    "        df_RTN = df_RTN.sort_values(by='Requested Date', ascending=False)\n",
    "        \n",
    "        \n",
    "        # Create a helper column for sorting that puts 'delivered' last\n",
    "        df_RTN['SortPriority'] = df_RTN['Status Normalized'].apply(lambda x: 1 if x == 'Delivered' else 0)\n",
    "        \n",
    "        # Sort by the helper column first, then by 'Status' if needed\n",
    "        df_RTN.sort_values(by=['SortPriority', 'Requested Date'], ascending=[True, False],inplace=True)\n",
    "        \n",
    "        # Remove duplicates by 'OrderNumber', keeping the first occurrence\n",
    "        df_RTN = df_RTN.drop_duplicates(subset='Order Number', keep='first')\n",
    "        \n",
    "          # Optionally, drop the helper column if no longer needed\n",
    "        df_RTN.drop(columns=['SortPriority'], inplace=True)\n",
    " \n",
    "# Sort data by most recent date, additionally change column names to join to OB data\n",
    "df_RTN_cleaned = df_RTN.sort_values(by='Requested Date',ascending=True)\n",
    "df_RTN_cleaned['Work Stream']='Return'\n",
    "df_RTN_cleaned=df_RTN_cleaned.drop(columns=['Requested Date','Status',])\n",
    "df_RTN_cleaned.rename(columns={'Status Normalized':'Latest Status','Last Tracking Status':'Status Non-Normalized','Order Number':'Original Order Number'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151ff2f-e071-43d4-99e5-9798d70db010",
   "metadata": {},
   "source": [
    "# Step 2: Join and Detect any Non-Normalized Status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1189dcd7-4aeb-4e97-a19a-b7bf07ea257f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Status Non-Normalized, Work Stream]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_LIT_cleaned = pd.concat([df_OB_cleaned,df_RTN_cleaned],ignore_index=True)\n",
    "# want to see non-normalized status's that need to be normalized\n",
    "non_norm=df_LIT_cleaned[df_LIT_cleaned['Latest Status'].isna()]\n",
    "print(non_norm[['Status Non-Normalized','Work Stream']])\n",
    "non_norm = non_norm[['Status Non-Normalized','Work Stream']]\n",
    "non_norm.to_excel(r\"W:\\Logistics\\Elliott\\Callum\\LIT\\Non Normalised Status\\Non Normalized Status.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4604c1e4-1e40-4901-b0d8-80c25b72e17c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_LIT_Final = df_Master.merge(df_LIT_cleaned,\n",
    "                                      left_on='Original Order Number',\n",
    "                                      right_on='Original Order Number',\n",
    "                                      how='left')\n",
    "df_LIT_Final = df_LIT_Final.fillna('No Data')\n",
    "df_LIT_Final['Carrier'] = df_LIT_Final['Carrier'].str.replace(r'\\s*\\(CS\\)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5177601b-b0f9-413a-b745-3764b35f91a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_filepath) as writer:\n",
    "   df_LIT_Final.to_excel(writer, sheet_name='Lost In Transit - Cleaned ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e9287-1f7d-4565-80b5-7640837a00d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7605671-9146-416e-b8a1-129efac95654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
